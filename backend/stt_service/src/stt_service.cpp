#include "stt_service.h"
#include <iostream>
#include <string>
#include <vector>
#include <future>
#include <atomic>
#include <random>
#include <sstream>
#include <iomanip>
#include <chrono>
#include <thread> 

#include "llm_engine_client.h" 
#include "azure_stt_client.h" 
#include <google/protobuf/empty.pb.h> 
#include "stt.pb.h" 
#include "llm.pb.h" // llm::SessionConfig ì‚¬ìš©ì„ ìœ„í•´ ì¶”ê°€

using grpc::Status;
using grpc::StatusCode;

namespace stt {

std::string STTServiceImpl::generate_uuid() {
    std::random_device rd;
    std::mt19937_64 gen(rd());
    std::uniform_int_distribution<uint64_t> dis;

    std::stringstream ss;
    ss << std::hex << std::setfill('0');
    ss << std::setw(16) << dis(gen);
    ss << std::setw(16) << dis(gen);
    return ss.str();
}

STTServiceImpl::STTServiceImpl(std::shared_ptr<AzureSTTClient> azure_client,
                               std::shared_ptr<LLMEngineClient> llm_client)
  : azure_stt_client_(azure_client), llm_engine_client_(llm_client)
{
    if (!azure_stt_client_) {
        throw std::runtime_error("AzureSTTClient cannot be null in STTServiceImpl.");
    }
    if (!llm_engine_client_) {
        throw std::runtime_error("LLMEngineClient cannot be null in STTServiceImpl.");
    }
}

Status STTServiceImpl::RecognizeStream(
    ServerContext* context,
    ServerReader<STTStreamRequest>* reader,
    google::protobuf::Empty* response 
) {
    const std::string client_peer = context->peer();
    std::string stt_internal_session_id; // STT ì„œë¹„ìŠ¤ ë‚´ë¶€ ì„¸ì…˜ ID
    std::string frontend_session_id;     // í”„ë¡ íŠ¸ì—”ë“œ ì›¹ì†Œì¼“ ì„¸ì…˜ ID

    std::cout << "âœ… STT_Service: New client connection from: " << client_peer << std::endl;

    std::string language;
    std::atomic<bool> azure_started{false};
    std::atomic<bool> llm_stream_started{false};
    std::atomic<bool> stream_error_occurred{false};
    std::string error_message_detail; // ìƒì„¸ ì˜¤ë¥˜ ë©”ì‹œì§€ ì €ì¥ìš©

    std::promise<void> azure_processing_complete_promise;
    auto azure_processing_complete_future = azure_processing_complete_promise.get_future();

    auto cleanup_resources = [&](bool stop_azure, bool finish_llm) {
         std::cout << "ğŸ§¹ STT_Service [STT_SID:" << (stt_internal_session_id.empty() ? "NO_STT_SID" : stt_internal_session_id) 
                   << ", FE_SID:" << (frontend_session_id.empty() ? "NO_FE_SID" : frontend_session_id)
                   << "] Cleaning up resources... StopAzure=" << stop_azure << ", FinishLLM=" << finish_llm << std::endl;
         if (finish_llm && llm_engine_client_ && llm_stream_started.load() && llm_engine_client_->IsStreamActive()) { // IsStreamActive ì¶”ê°€
             std::cout << "   Finishing LLM stream for FE_SID [" << frontend_session_id << "]..." << std::endl;
             grpc::Status llm_status = llm_engine_client_->FinishStream();
             if (!llm_status.ok()) {
                  std::cerr << "   âš ï¸ LLM stream finish error during cleanup: (" << llm_status.error_code() << ") "
                            << llm_status.error_message() << std::endl;
             } else {
                  std::cout << "   LLM stream finished successfully during cleanup for FE_SID [" << frontend_session_id << "]." << std::endl;
             }
             llm_stream_started.store(false);
         }
         if (stop_azure && azure_stt_client_ && azure_started.load()) {
              std::cout << "   Stopping Azure recognition for STT_SID [" << stt_internal_session_id << "]..." << std::endl;
              azure_stt_client_->StopContinuousRecognition();
              azure_started.store(false);
         }
    };

    try {
        STTStreamRequest initial_request;
        std::cout << "   STT_Service: Waiting for initial RecognitionConfig from client " << client_peer << "..." << std::endl;
        if (!reader->Read(&initial_request)) {
            error_message_detail = "Failed to read initial request from client.";
            std::cerr << "âŒ STT_Service [Peer:" << client_peer << "] " << error_message_detail << std::endl;
            return Status(StatusCode::INVALID_ARGUMENT, error_message_detail);
        }
        
        if (initial_request.request_data_case() != STTStreamRequest::kConfig) {
            error_message_detail = "Initial request must be RecognitionConfig.";
            std::cerr << "âŒ STT_Service [Peer:" << client_peer << "] " << error_message_detail << std::endl;
            return Status(StatusCode::INVALID_ARGUMENT, error_message_detail);
        }

        const auto& received_config = initial_request.config();
        language = received_config.language();
        frontend_session_id = received_config.frontend_session_id(); // â˜… frontend_session_id ì¶”ì¶œ
        stt_internal_session_id = received_config.session_id();      // STT ë‚´ë¶€ìš© ì„¸ì…˜ ID (websocket_gatewayê°€ ì „ë‹¬)
        
        if (stt_internal_session_id.empty()) { // í˜¹ì‹œ websocket_gatewayê°€ ì•ˆì¤¬ë‹¤ë©´ ìƒì„±
            stt_internal_session_id = generate_uuid();
        }

        // â˜… frontend_session_id ìœ íš¨ì„± ê²€ì‚¬ (í•„ìˆ˜)
        if (frontend_session_id.empty()) {
            error_message_detail = "CRITICAL: frontend_session_id is missing in RecognitionConfig from websocket_gateway.";
            std::cerr << "âŒ STT_Service [STT_SID:" << stt_internal_session_id << "] " << error_message_detail << std::endl;
            // ì´ ê²½ìš°, í´ë¼ì´ì–¸íŠ¸(websocket_gateway)ì—ê²Œ ì˜¤ë¥˜ë¥¼ ì•Œë¦¬ê³  ìŠ¤íŠ¸ë¦¼ì„ ì¢…ë£Œí•´ì•¼ í•¨
            return Status(StatusCode::INVALID_ARGUMENT, error_message_detail);
        }
        if (language.empty()) {
           error_message_detail = "Language code is missing in RecognitionConfig.";
           std::cerr << "âŒ STT_Service [STT_SID:" << stt_internal_session_id << ", FE_SID:" << frontend_session_id << "] " << error_message_detail << std::endl;
           return Status(StatusCode::INVALID_ARGUMENT, error_message_detail);
        }
        std::cout << "   STT_Service [STT_SID:" << stt_internal_session_id 
                  << ", FE_SID:" << frontend_session_id 
                  << "] Config received: Language=" << language 
                  << ", Received STT SID from Gateway: " << received_config.session_id() 
                  << ", Received FE SID from Gateway: " << received_config.frontend_session_id() << std::endl;
        std::cout << "   STT_Service: Received RecognitionConfig (ShortDebugString): " << received_config.ShortDebugString() << std::endl; // ìƒì„¸ ë¡œê¹…


        std::cout << "   STT_Service [STT_SID:" << stt_internal_session_id << "] Starting stream to LLM Engine for FE_SID [" << frontend_session_id << "]..." << std::endl;
        llm::SessionConfig llm_config_to_send; 
        llm_config_to_send.set_frontend_session_id(frontend_session_id);       
        llm_config_to_send.set_session_id(stt_internal_session_id); // STTì˜ ë‚´ë¶€ ì„¸ì…˜ IDë¥¼ LLMì˜ ë‚´ë¶€ ì„¸ì…˜ IDë¡œ ì „ë‹¬ (ì„ íƒì )
        
        std::cout << "   STT_Service: Sending SessionConfig to LLM: " << llm_config_to_send.ShortDebugString() << std::endl; // ì „ì†¡ ì „ ë¡œê¹…

        if (!llm_engine_client_->StartStream(llm_config_to_send)) {
            error_message_detail = "Failed to start stream to LLM Engine.";
            std::cerr << "âŒ STT_Service [STT_SID:" << stt_internal_session_id << ", FE_SID:" << frontend_session_id << "] " << error_message_detail << std::endl;
            stream_error_occurred.store(true);
            // cleanup_resourcesëŠ” ì´ í•¨ìˆ˜ì˜ ëì—ì„œ í˜¸ì¶œë˜ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” ìƒíƒœë§Œ ì„¤ì •
            return Status(StatusCode::INTERNAL, error_message_detail);
        }
        llm_stream_started.store(true);
        std::cout << "   STT_Service [STT_SID:" << stt_internal_session_id << "] LLM stream started successfully for FE_SID [" << frontend_session_id << "]." << std::endl;


        auto text_callback =
            [this, stt_sid = stt_internal_session_id, fe_sid = frontend_session_id, &stream_error_occurred, &error_message_detail, llm_client = llm_engine_client_]
            (const std::string& text, bool is_final) { 
            if (stream_error_occurred.load()) return;
            // std::cout << "   STT_Service [STT_SID:" << stt_sid << ", FE_SID:" << fe_sid << "] Azure Text (is_final=" << is_final << "): '" << text << "'" << std::endl;
            if (!llm_client->SendTextChunk(text)) { // SendTextChunkëŠ” is_final ì¸ìë¥¼ ë°›ì§€ ì•ŠìŒ
                std::cerr << "âŒ STT_Service [STT_SID:" << stt_sid << ", FE_SID:" << fe_sid << "] Error sending text chunk to LLM Engine. Marking stream as error." << std::endl;
                if (!stream_error_occurred.load()) {
                     error_message_detail = "Failed to forward text chunk to LLM engine.";
                     stream_error_occurred.store(true);
                }
            }
        };

        auto completion_callback =
            [this, stt_sid = stt_internal_session_id, fe_sid = frontend_session_id, &stream_error_occurred, &error_message_detail, &azure_processing_complete_promise]
            (bool success, const std::string& azure_msg) {
             std::cout << "â„¹ï¸ STT_Service [STT_SID:" << stt_sid << ", FE_SID:" << fe_sid << "] Azure STT processing finished. Success: " << success << std::endl;
             if (!success) {
                 std::cerr << "   Azure STT Error: " << azure_msg << std::endl;
                 if (!stream_error_occurred.load()) {
                     error_message_detail = "Azure STT recognition failed: " + azure_msg;
                     stream_error_occurred.store(true);
                 }
             }
             try {
                 azure_processing_complete_promise.set_value();
             } catch (const std::future_error& e) {
                  std::cerr << "â„¹ï¸ STT_Service [STT_SID:" << stt_sid << "] Promise already set in completion_callback: " << e.what() << std::endl;
             }
        };

        std::cout << "   STT_Service [STT_SID:" << stt_internal_session_id << "] Starting Azure continuous recognition..." << std::endl;
        if (!azure_stt_client_->StartContinuousRecognition(language, text_callback, completion_callback)) {
            error_message_detail = "Failed to start Azure continuous recognition.";
            std::cerr << "âŒ STT_Service [STT_SID:" << stt_internal_session_id << ", FE_SID:" << frontend_session_id << "] " << error_message_detail << std::endl;
            stream_error_occurred.store(true);
            // cleanup_resources(false, true); // LLM ìŠ¤íŠ¸ë¦¼ë§Œ ì •ë¦¬ ì‹œë„ (í•¨ìˆ˜ ëì—ì„œ ì¼ê´„ ì²˜ë¦¬)
            return Status(StatusCode::INTERNAL, error_message_detail);
        }
        azure_started.store(true);
        std::cout << "   STT_Service [STT_SID:" << stt_internal_session_id << "] Azure recognition started successfully." << std::endl;

        STTStreamRequest audio_request;
        size_t total_bytes_received = 0;
        std::cout << "   STT_Service [STT_SID:" << stt_internal_session_id << "] Waiting for audio chunks from client..." << std::endl;
        while (!stream_error_occurred.load() && reader->Read(&audio_request)) {
            if (context->IsCancelled()) {
                 std::cout << "   STT_Service [STT_SID:" << stt_internal_session_id << "] Client cancelled the request." << std::endl;
                 error_message_detail = "Request cancelled by client.";
                 stream_error_occurred.store(true);
                 break;
            }

            if (audio_request.request_data_case() == STTStreamRequest::kAudioChunk) {
                const auto& chunk_data_str = audio_request.audio_chunk(); // proto bytes is std::string
                if (!chunk_data_str.empty()) {
                    total_bytes_received += chunk_data_str.size();
                    azure_stt_client_->PushAudioChunk(
                        reinterpret_cast<const uint8_t*>(chunk_data_str.data()),
                        chunk_data_str.size()
                    );
                }
            } else if (audio_request.request_data_case() == STTStreamRequest::REQUEST_DATA_NOT_SET) {
                 std::cerr << "âš ï¸ STT_Service [STT_SID:" << stt_internal_session_id << "] Received request with data not set." << std::endl;
            } else { // Configê°€ ë˜ ë“¤ì–´ì˜¨ ê²½ìš° ë“±
                  std::cerr << "âš ï¸ STT_Service [STT_SID:" << stt_internal_session_id << "] Received unexpected non-audio chunk data after config (type: "
                            << audio_request.request_data_case() << "). Ignoring." << std::endl;
            }
        } 

        if (stream_error_occurred.load()) {
              std::cerr << "âŒ STT_Service [STT_SID:" << stt_internal_session_id << ", FE_SID:" << frontend_session_id 
                        << "] Error occurred, exiting audio reading loop. Reason: " << error_message_detail << std::endl;
        } else {
              std::cout << "â„¹ï¸ STT_Service [STT_SID:" << stt_internal_session_id << ", FE_SID:" << frontend_session_id 
                        << "] Client finished sending audio. Total bytes received: " << total_bytes_received << "." << std::endl;
        }

        if (azure_started.load()) {
            std::cout << "   STT_Service [STT_SID:" << stt_internal_session_id << "] Signaling Azure to stop continuous recognition." << std::endl;
            azure_stt_client_->StopContinuousRecognition();
        }

        std::cout << "   STT_Service [STT_SID:" << stt_internal_session_id << "] Waiting for Azure STT processing to complete..." << std::endl;
        std::future_status wait_status = azure_processing_complete_future.wait_for(std::chrono::seconds(30));
        if (wait_status == std::future_status::timeout) {
             std::cerr << "âŒ STT_Service [STT_SID:" << stt_internal_session_id << ", FE_SID:" << frontend_session_id 
                       << "] Timed out waiting for Azure STT completion (30s)." << std::endl;
             if (!stream_error_occurred.load()) {
                 error_message_detail = "Timeout waiting for Azure STT completion.";
                 stream_error_occurred.store(true);
             }
        } else {
             std::cout << "   STT_Service [STT_SID:" << stt_internal_session_id << "] Azure STT processing completed or error signal received." << std::endl;
        }

        Status final_llm_status = Status::OK;
        if (llm_stream_started.load()) {
             std::cout << "   STT_Service [STT_SID:" << stt_internal_session_id << "] Finishing LLM engine stream for FE_SID [" << frontend_session_id << "]..." << std::endl;
             grpc::Status llm_status = llm_engine_client_->FinishStream();
             final_llm_status = llm_status;
             llm_stream_started.store(false);

             if (!llm_status.ok()) {
                 std::cerr << "âŒ STT_Service [STT_SID:" << stt_internal_session_id << ", FE_SID:" << frontend_session_id 
                           << "] LLM stream finish error: (" << llm_status.error_code() << ") "
                           << llm_status.error_message() << std::endl;
                  if (!stream_error_occurred.load()) {
                     error_message_detail = "Failed to finish LLM stream: " + llm_status.error_message();
                     stream_error_occurred.store(true);
                  }
             } else {
                  std::cout << "   STT_Service [STT_SID:" << stt_internal_session_id << "] LLM stream finished successfully for FE_SID [" << frontend_session_id << "]." << std::endl;
             }
        } else {
             std::cout << "   STT_Service [STT_SID:" << stt_internal_session_id << "] LLM stream was not started or already finished, skipping finish." << std::endl;
        }

        std::cout << "ğŸ STT_Service [STT_SID:" << stt_internal_session_id << ", FE_SID:" << frontend_session_id << "] Processing complete. Final status check." << std::endl;
        if (stream_error_occurred.load()) {
            if (context->IsCancelled()) { // í´ë¼ì´ì–¸íŠ¸ê°€ ëª…ì‹œì ìœ¼ë¡œ ì·¨ì†Œí•œ ê²½ìš°
                std::cerr << "âŒ STT_Service [STT_SID:" << stt_internal_session_id << "] Returning CANCELLED status due to client cancellation." << std::endl;
                 // cleanup_resourcesëŠ” finally ë¸”ë¡ì²˜ëŸ¼ ì—¬ê¸°ì„œ í˜¸ì¶œë  ê²ƒì„
                return Status(StatusCode::CANCELLED, "Request cancelled by client during processing: " + error_message_detail);
            }
            // LLM ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ ì˜¤ë¥˜ê°€ ìµœì¢… ì˜¤ë¥˜ì¸ ê²½ìš° í•´ë‹¹ ìƒíƒœ ë°˜í™˜
            if (!final_llm_status.ok() && final_llm_status.error_code() != StatusCode::CANCELLED) { // LLM ì˜¤ë¥˜ê°€ ì·¨ì†Œê°€ ì•„ë‹ˆë¼ë©´
                 std::cerr << "âŒ STT_Service [STT_SID:" << stt_internal_session_id << "] Returning LLM finish error status: (" 
                           << final_llm_status.error_code() << ")" << std::endl;
                 return final_llm_status;
            }
            // ê·¸ ì™¸ ë‚´ë¶€ ì˜¤ë¥˜
            std::cerr << "âŒ STT_Service [STT_SID:" << stt_internal_session_id << "] Returning INTERNAL error status: " << error_message_detail << std::endl;
            return Status(StatusCode::INTERNAL, "An internal error occurred in STT service: " + error_message_detail);
        } else {
            std::cout << "âœ… STT_Service [STT_SID:" << stt_internal_session_id << "] Returning OK status." << std::endl;
            return Status::OK;
        }

    } catch (const std::exception& e) {
        std::cerr << "âŒ STT_Service [STT_SID:" << (stt_internal_session_id.empty() ? "N/A" : stt_internal_session_id) 
                  << ", FE_SID:" << (frontend_session_id.empty() ? "N/A" : frontend_session_id)
                  << "] Unhandled exception in RecognizeStream: " << e.what() << std::endl;
        stream_error_occurred.store(true); // ì˜¤ë¥˜ í”Œë˜ê·¸ ì„¤ì •
        error_message_detail = "Unhandled exception: " + std::string(e.what());
        // cleanup_resourcesëŠ” í•¨ìˆ˜ ì¢…ë£Œ ì‹œ í˜¸ì¶œë¨
        return Status(StatusCode::UNKNOWN, "An unknown exception occurred in the STT service handler.");
    } catch (...) {
         std::cerr << "âŒ STT_Service [STT_SID:" << (stt_internal_session_id.empty() ? "N/A" : stt_internal_session_id) 
                   << ", FE_SID:" << (frontend_session_id.empty() ? "N/A" : frontend_session_id)
                   << "] Unknown non-standard exception in RecognizeStream." << std::endl;
         stream_error_occurred.store(true);
         error_message_detail = "Unknown non-standard exception.";
         return Status(StatusCode::UNKNOWN, "An unknown non-standard exception occurred.");
    }
}

} // namespace stt
