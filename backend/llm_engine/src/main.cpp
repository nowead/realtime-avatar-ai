#include <grpcpp/grpcpp.h>
#include <cstdlib> // For getenv
#include <iostream>
#include <string>
#include <memory>
#include <stdexcept>
#include <csignal> // For signal handling
#include <atomic>
#include <thread> // For sleep_for

// Include our service and client headers
// llm_service.h ê°€ ë‹¤ë¥¸ í—¤ë”ë“¤ì„ í¬í•¨í•˜ë¯€ë¡œ, ì•„ë˜ ë‘ ê°œëŠ” í•„ìš” ì—†ì„ ìˆ˜ ìˆìŒ
#include "llm_service.h"
// #include "tts_client.h" // llm_service.h ì—ì„œ í¬í•¨ë¨ (ì•„ë§ˆë„)
// #include "openai_client.h" // llm_service.h ì—ì„œ í¬í•¨ë¨ (ì•„ë§ˆë„)

// Global shutdown flag and server pointer
std::atomic<bool> shutdown_requested(false);
std::unique_ptr<grpc::Server> server_ptr = nullptr;

// Signal handler
void signalHandler(int signum) {
    std::cout << "\nâ„¹ï¸ Interrupt signal (" << signum << ") received. Shutting down LLM engine..." << std::endl;
    shutdown_requested.store(true);
    if (server_ptr) {
        // Use a deadline for graceful shutdown (e.g., 5 seconds)
        server_ptr->Shutdown(std::chrono::system_clock::now() + std::chrono::seconds(5));
        // Alternatively, immediate shutdown: server_ptr->Shutdown();
    }
}

int main() {
    signal(SIGINT, signalHandler);
    signal(SIGTERM, signalHandler);

    std::cout << "ğŸš€ Starting LLM Engine Service..." << std::endl;

    // --- Load Environment Variables ---
    const char* openai_key_env = std::getenv("OPENAI_API_KEY");
    const char* tts_addr_env = std::getenv("TTS_SERVICE_ADDRESS");
    const char* server_addr_env = std::getenv("LLM_SERVER_ADDRESS");
    const char* openai_model_env = std::getenv("OPENAI_MODEL"); // Optional

    // Mandatory variables
    if (!openai_key_env || std::string(openai_key_env).empty()) {
        std::cerr << "âŒ FATAL: Missing or empty OPENAI_API_KEY environment variable. Exiting." << std::endl;
        return 1;
    }
    if (!tts_addr_env || std::string(tts_addr_env).empty()) {
        std::cerr << "âŒ FATAL: Missing or empty TTS_SERVICE_ADDRESS environment variable. Exiting." << std::endl;
        return 1;
    }

    std::string openai_api_key = openai_key_env;
    std::string tts_service_address = tts_addr_env;
    std::string llm_server_address = (server_addr_env && !std::string(server_addr_env).empty())
                                     ? server_addr_env : "0.0.0.0:50052"; // Default port for LLM
    std::string openai_model = (openai_model_env && !std::string(openai_model_env).empty())
                                ? openai_model_env : "gpt-4o"; // Default model


    std::cout << "ğŸ”§ Configuration:" << std::endl;
    // std::cout << "  OpenAI API Key: [REDACTED]" << std::endl; // Don't log the key
    std::cout << "  OpenAI Model: " << openai_model << std::endl;
    std::cout << "  TTS Service Address: " << tts_service_address << std::endl;
    std::cout << "  LLM Service Listening Address: " << llm_server_address << std::endl;

    // Pointers for graceful shutdown
    std::shared_ptr<llm_engine::TTSClient> tts_client = nullptr;
    std::shared_ptr<llm_engine::OpenAIClient> openai_client = nullptr;
    std::unique_ptr<llm_engine::LLMServiceImpl> service_impl = nullptr;

    try {
        // --- Instantiate Clients and Service ---
        std::cout << "â³ Initializing TTS client..." << std::endl;

        // ===== TTSClient ìƒì„± ë°©ì‹ ìˆ˜ì • =====
        // 1. TTS ì„œë²„ ì£¼ì†Œë¥¼ ì‚¬ìš©í•˜ì—¬ gRPC ì±„ë„ ìƒì„±
        std::cout << "   Creating gRPC channel for TTS server at: " << tts_service_address << std::endl;
        //    InsecureChannelCredentials ì‚¬ìš© (í•„ìš”ì‹œ SecureCredentials ë¡œ ë³€ê²½)
        std::shared_ptr<grpc::Channel> tts_channel = grpc::CreateChannel(
            tts_service_address, grpc::InsecureChannelCredentials()
        );

        if (!tts_channel) {
            // ì±„ë„ ìƒì„± ì‹¤íŒ¨ ì‹œ ì˜¤ë¥˜ ì²˜ë¦¬
            throw std::runtime_error("Failed to create gRPC channel for TTS server at " + tts_service_address);
        }
        std::cout << "   gRPC channel for TTS created." << std::endl;

        // 2. ìƒì„±ëœ ì±„ë„ì„ ì‚¬ìš©í•˜ì—¬ TTSClient ê°ì²´ ìƒì„± (std::make_shared ì‚¬ìš©)
        //    ì´ì œ std::shared_ptr<grpc::Channel> ì„ ë°›ëŠ” ìƒì„±ìê°€ í˜¸ì¶œë¨
        tts_client = std::make_shared<llm_engine::TTSClient>(tts_channel);
        std::cout << "âœ… TTS client initialized." << std::endl;
        // ===== End TTSClient ìƒì„± ë°©ì‹ ìˆ˜ì • =====


        std::cout << "â³ Initializing OpenAI client..." << std::endl;
        openai_client = std::make_shared<llm_engine::OpenAIClient>(openai_api_key, openai_model);
        std::cout << "âœ… OpenAI client initialized." << std::endl;

        std::cout << "â³ Creating LLM service implementation..." << std::endl;
        // LLMServiceImpl ìƒì„±ìì— ìˆ˜ì •ëœ tts_client ì „ë‹¬
        service_impl = std::make_unique<llm_engine::LLMServiceImpl>(tts_client, openai_client);
        std::cout << "âœ… LLM service implementation created." << std::endl;

        // --- Setup and Start gRPC Server ---
        grpc::ServerBuilder builder;
        grpc::EnableDefaultHealthCheckService(true);

        builder.AddListeningPort(llm_server_address, grpc::InsecureServerCredentials());
        builder.RegisterService(service_impl.get());

        std::cout << "â³ Building and starting gRPC server..." << std::endl;
        server_ptr = builder.BuildAndStart(); // Assign to global pointer

        if (server_ptr) {
            std::cout << "âœ… LLM gRPC server listening at " << llm_server_address << std::endl;
            // ì„œë²„ ì¢…ë£Œ ì‹œê·¸ë„ ëŒ€ê¸° (WaitëŠ” ë¸”ë¡œí‚¹ í•¨ìˆ˜)
            server_ptr->Wait();
            // Wait() í•¨ìˆ˜ê°€ ë°˜í™˜ë˜ë©´ ì¢…ë£Œ ì‹œí€€ìŠ¤ ì‹œì‘
            std::cout << "â„¹ï¸ Server Wait() returned. Proceeding with shutdown..." << std::endl;
        } else {
            // ì„œë²„ ì‹œì‘ ì‹¤íŒ¨
            throw std::runtime_error("Failed to start LLM gRPC server on " + llm_server_address);
        }

    } catch (const std::exception& e) {
        std::cerr << "âŒ FATAL Exception during initialization or runtime: " << e.what() << ". Exiting." << std::endl;
        // Clean up order matters less on fatal exception
        server_ptr.reset(); // Ensure server is reset if already created
        service_impl.reset();
        openai_client.reset();
        tts_client.reset();
        return 1;
    } catch (...) {
        std::cerr << "âŒ FATAL Unknown exception caught during initialization or runtime. Exiting." << std::endl;
        server_ptr.reset();
        service_impl.reset();
        openai_client.reset();
        tts_client.reset();
        return 1;
    }

    // --- Graceful Shutdown (Wait() ë°˜í™˜ í›„ ë˜ëŠ” ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ì—ì„œ Shutdown() í˜¸ì¶œ í›„ ë„ë‹¬) ---
    std::cout << "â„¹ï¸ Server shutdown sequence initiated." << std::endl;

    // ëª…ì‹œì ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ í•´ì œ (ìŠ¤ë§ˆíŠ¸ í¬ì¸í„°ê°€ ì²˜ë¦¬í•˜ì§€ë§Œ, ìˆœì„œê°€ ì¤‘ìš”í•  ìˆ˜ ìˆìŒ)
    // server_ptr->Shutdown() ì€ ì´ë¯¸ signalHandler ë˜ëŠ” Wait() ë°˜í™˜ ì „ì— í˜¸ì¶œë˜ì—ˆì–´ì•¼ í•¨
    service_impl.reset(); // ì„œë¹„ìŠ¤ ì¢…ë£Œ -> ì§„í–‰ ì¤‘ì¸ í˜¸ì¶œ ì™„ë£Œ ëŒ€ê¸° (Shutdown deadline ë‚´ì—ì„œ)
    std::cout << "  LLM service implementation released." << std::endl;
    openai_client.reset(); // í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ
    std::cout << "  OpenAI client released." << std::endl;
    tts_client.reset();
    std::cout << "  TTS client released." << std::endl;
    server_ptr.reset(); // ì„œë²„ í¬ì¸í„° ìµœì¢… í•´ì œ
    std::cout << "  gRPC server pointer released." << std::endl;


    std::cout << "âœ… LLM Engine Service shut down gracefully." << std::endl;
    return 0;
}