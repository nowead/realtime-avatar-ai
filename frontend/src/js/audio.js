// src/js/audio.js

// ì˜¤ë””ì˜¤ ì²­í¬ ë³‘í•© ìœ í‹¸
function mergeChunks(chunks) {
  const totalLength = chunks.reduce((sum, c) => sum + c.length, 0);
  const merged = new Int16Array(totalLength);
  let offset = 0;
  for (const chunk of chunks) {
    merged.set(chunk, offset);
    offset += chunk.length;
  }
  return merged;
}

// ì˜¤ë””ì˜¤ ì„œë¹„ìŠ¤ ê°ì²´
const AudioService = {
  audioContext: null,
  micStream: null,
  workletNode: null,
  onVADFrame: null,

  async initialize(sampleRate = 16000) {
    this.audioContext = new AudioContext({ sampleRate });

    // ðŸ”¥ Webpack í™˜ê²½ì—ì„œëŠ” public/ ë””ë ‰í† ë¦¬ ê¸°ì¤€ ê²½ë¡œì—¬ì•¼ í•¨!
    await this.audioContext.audioWorklet.addModule('/worklets/audio-worklet-processor.js');

    this.micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const source = this.audioContext.createMediaStreamSource(this.micStream);

    this.workletNode = new AudioWorkletNode(this.audioContext, 'mic-processor');
    source.connect(this.workletNode);

    this.workletNode.port.onmessage = (e) => {
      if (this.onVADFrame) {
        this.onVADFrame(e.data); // e.data: Int16Array
      } else {
        console.warn('[AudioService] onVADFrame not set!');
      }
    };

    console.log('[AudioService] AudioWorklet initialized.');
  },

  stop() {
    if (this.workletNode) {
      this.workletNode.disconnect();
      this.workletNode = null;
    }
    if (this.micStream) {
      this.micStream.getTracks().forEach(track => track.stop());
      this.micStream = null;
    }
    if (this.audioContext) {
      this.audioContext.close();
      this.audioContext = null;
    }
    console.log('[AudioService] stopped.');
  }
};

export { AudioService, mergeChunks };
